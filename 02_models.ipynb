{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f534603",
   "metadata": {},
   "source": [
    "# LLM\n",
    "\n",
    "Modelos de Linguagem Grande (LLMs, na sigla em inglês) são um componente central do LangChain. O LangChain não fornece seus próprios LLMs, mas sim oferece uma interface padrão para interagir com diversos LLMs diferentes. Para ser específico, essa interface é uma que recebe como entrada uma string e retorna uma string.\n",
    "\n",
    "Existem muitos provedores de LLMs (OpenAI, Cohere, Hugging Face, etc) - a classe LLM é projetada para fornecer uma interface padrão para todos eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68692f46",
   "metadata": {},
   "source": [
    "# Chamando a LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = \"Qual a capital do Brasil?\"\n",
    "llm.invoke(pergunta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3de7a",
   "metadata": {},
   "source": [
    "# Chamando com stream de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ce445",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = \"Conte uma história rápida sobre a jornada de aprender a programar\"\n",
    "\n",
    "for trecho in llm.stream(pergunta):\n",
    "  print(trecho, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1094118",
   "metadata": {},
   "source": [
    "# Chamadas simultâneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "perguntas = [\n",
    "  \"O que é o céu?\",\n",
    "  \"O que é a terra?\",\n",
    "  \"O que são as estrelas?\",\n",
    "]\n",
    "\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f5fb7",
   "metadata": {},
   "source": [
    "# ChatModels\n",
    "\n",
    "ChatModels são um componente central do LangChain.\n",
    "\n",
    "Um modelo de chat é um modelo de linguagem que utiliza mensagens de chat como entradas e retorna mensagens de chat como saídas (ao invés de usar texto puro).\n",
    "\n",
    "O LangChain possui integrações com vários provedores de modelos (OpenAI, Cohere, Hugging Face, etc.) e expõe uma interface padrão para interagir com todos esses modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b7994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "  SystemMessage(content=\"Você é um assistente que conta piadas\"),\n",
    "  HumanMessage(content=\"Quanto é 1 + 1?\"),\n",
    "]\n",
    "\n",
    "resposta = chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dcacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de244e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2aa1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "mensagens = [\n",
    "  SystemMessage(content=\"Você é um assistente que conta piadas\"),\n",
    "  HumanMessage(content=\"Quanto é 1 + 1?\"),\n",
    "]\n",
    "\n",
    "for trecho in chat.stream(mensagens):\n",
    "  print(trecho.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c42d344",
   "metadata": {},
   "source": [
    "Existem 5 tipos diferentes de mensagens:\n",
    "\n",
    "- `HumanMessage`: isso representa uma mensagem do usuário. Geralmente consiste apenas de conteúdo.\n",
    "\n",
    "- `AIMessage`: isso representa uma mensagem do modelo. Pode ter additional_kwargs incluídos - por exemplo, tool_calls se estiver usando chamadas de ferramentas da OpenAI.\n",
    "\n",
    "- `SystemMessage`: isso representa uma mensagem do sistema, que indica ao modelo como se comportar. Geralmente consiste apenas do conteúdo. Nem todo modelo suporta isso.\n",
    "\n",
    "- `FunctionMessage`: isso representa o resultado de uma chamada de função. Além do papel e conteúdo, esta mensagem tem um parâmetro de nome que transmite o nome da função que foi chamada para produzir este resultado.\n",
    "\n",
    "- `ToolMessage`: isso representa o resultado de uma chamada de ferramenta. Isso é distinto de uma mensagem de função a fim de corresponder aos tipos de mensagens de função e ferramenta da OpenAI. Além do papel e conteúdo, esta mensagem tem um parâmetro tool_call_id que transmite o id da chamada à ferramenta que foi feita para produzir este resultado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
