{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2846e37a",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "A maioria das aplicações de Modelos de LLM possui uma interface conversacional. Um componente essencial de uma conversa é a capacidade de se referir a informações introduzidas anteriormente na conversa. No mínimo, um sistema conversacional deve ser capaz de acessar diretamente alguma janela de mensagens passadas. Um sistema mais complexo precisará ter um modelo de mundo que está constantemente atualizando, o que lhe permite fazer coisas como manter informações sobre entidades e suas relações.\n",
    "\n",
    "Chamamos essa capacidade de armazenar informações sobre interações passadas de \"Memory\", ou memória. LangChain oferece muitas utilidades para adicionar memória a um sistema. Essas utilidades podem ser usadas por si só ou incorporadas de maneira integrada em uma chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e25260a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "memory = InMemoryChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d4be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando mensagens ao histórico de chat\n",
    "memory.add_user_message('Olá, modelo!')\n",
    "# Adicionando mensagem do modelo\n",
    "memory.add_ai_message('Olá, user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce644a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Olá, modelo!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Olá, user', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93cc2d",
   "metadata": {},
   "source": [
    "## Criando uma conversa com memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b0acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um tutor de programação chamado Asimo. Responda as perguntas de forma didática.\"),\n",
    "    (\"placeholder\", \"{memoria}\"),\n",
    "    (\"human\", \"{pergunta}\"),\n",
    "])\n",
    "chain = prompt | ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510b6f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "def get_by_session_id(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "chain_com_memoria = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,\n",
    "    input_messages_key='pergunta',\n",
    "    history_messages_key='memoria'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51b01133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Olá, Adriano! Como posso te ajudar hoje?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 40, 'total_tokens': 54, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CTMAPyI4uNEbFIhuoEn05Ohm7snJR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1180bfad-f994-49d2-ad4c-7df6a92d6bfe-0', usage_metadata={'input_tokens': 40, 'output_tokens': 14, 'total_tokens': 54, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable': {'session_id': 'usuaria_a'}}\n",
    "resposta = chain_com_memoria.invoke({'pergunta': 'O meu nome é Adriano'}, config=config)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9458a0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Seu nome é Adriano. Posso te ajudar com alguma outra dúvida?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 68, 'total_tokens': 88, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CTMCKXykeReH4oLw5FBhMcN4wlXnQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d17a13a1-80a7-45c1-bbf0-7b2cd8e0d138-0', usage_metadata={'input_tokens': 68, 'output_tokens': 20, 'total_tokens': 88, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta = chain_com_memoria.invoke({'pergunta': 'Qual é o meu nome?'}, config=config)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39fb732a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Desculpe, como um assistente de IA, eu não tenho acesso a informações pessoais sobre usuários. Como posso te ajudar com programação hoje?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 40, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CTMCsGVCxrSrdTOWTo7awOUMOSVb6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--74b32e88-c148-41d0-87d6-e5e20ac6c0a9-0', usage_metadata={'input_tokens': 40, 'output_tokens': 35, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable': {'session_id': 'usuaria_b'}}\n",
    "resposta = chain_com_memoria.invoke({'pergunta': 'Qual é o meu nome?'}, config=config)\n",
    "resposta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
