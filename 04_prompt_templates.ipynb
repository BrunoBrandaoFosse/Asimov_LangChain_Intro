{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d90fb3a6",
   "metadata": {},
   "source": [
    "# Prompt Templates\n",
    "\n",
    "Um prompt para um modelo de linguagem é um conjunto de instruções ou entradas fornecidas por um usuário para guiar a resposta do modelo, ajudando-o a entender o contexto e gerar uma saída baseada em linguagem relevante e coerente, como responder a perguntas, completar frases ou participar de uma conversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29301801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Responda a seguinte pergunta do usuário:\n",
    "{pergunta}\n",
    "\"\"\")\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197053b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.format(pergunta=\"O que é um buraco negro?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Responda a seguinte pergunta do usuário em até {n_palavras} palavras:\n",
    "{pergunta}\n",
    "\"\"\")\n",
    "\n",
    "prompt_template.format(\n",
    "  pergunta=\"O que é um buraco negro?\",\n",
    "  n_palavras=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807028f0",
   "metadata": {},
   "source": [
    "### Valores **default**\n",
    "\n",
    "Usando **partial_variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679eaac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "Responda a seguinte pergunta do usuário em até {n_palavras} palavras:\n",
    "{pergunta}\n",
    "\"\"\", partial_variables={\"n_palavras\": 50})\n",
    "\n",
    "prompt_template.format(pergunta=\"O que é um buraco negro?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690cd51",
   "metadata": {},
   "source": [
    "## Composing prompts | Unindo múltiplos prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18867ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template_word_count = PromptTemplate.from_template(\"\"\"\n",
    "Responda a pergunta em até {n_palavras} palavras.\n",
    "\"\"\")\n",
    "\n",
    "template_lingua = PromptTemplate.from_template(\"\"\"\n",
    "Retorna a resposta em {lingua}.\n",
    "\"\"\")\n",
    "\n",
    "template_final = (\n",
    "  template_word_count\n",
    "  + template_lingua\n",
    "  + 'Responda a pergunta seguinte seguindo as instruções: {pergunta}'\n",
    ")\n",
    "\n",
    "template_final.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template_final.format(pergunta=\"O que é um buraco negro?\", lingua=\"inglês\", n_palavras=10)\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c76a8",
   "metadata": {},
   "source": [
    "# Templates para Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_template(\"Essa é a minha dúvida: {duvida}\")\n",
    "chat_template.format_messages(duvida=\"Quem sou eu?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "  [\n",
    "    ('system', 'Você é um assistente engraçado e se chama {nome_assistente}'),\n",
    "    ('human', 'Olá, como vai?'),\n",
    "    ('ai', 'Melhor agora! Como posso ajudá-lo?'),\n",
    "    ('human', '{pergunta}')\n",
    "  ]\n",
    ")\n",
    "\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template.format_messages(\n",
    "  nome_assistente=\"Asimo\",\n",
    "  pergunta=\"Qual é o seu nome?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2caa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "chat.invoke(chat_template.format_messages(\n",
    "  nome_assistente=\"Asimo\",\n",
    "  pergunta=\"Qual é o seu nome?\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3fdf14",
   "metadata": {},
   "source": [
    "# Template de Few-Shot Prompting para LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ccf5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplos = [\n",
    "    {\"pergunta\": \"Quem viveu mais tempo, Muhammad Ali ou Alan Turing?\", \n",
    "     \"resposta\": \n",
    "     \"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quantos anos Muhammad Ali tinha quando morreu? \n",
    "Resposta intermediária: Muhammad Ali tinha 74 anos quando morreu. \n",
    "Pergunta de acompanhamento: Quantos anos Alan Turing tinha quando morreu? \n",
    "Resposta intermediária: Alan Turing tinha 41 anos quando morreu. \n",
    "Então a resposta final é: Muhammad Ali \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quando nasceu o fundador do craigslist?\", \n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem foi o fundador do craigslist? \n",
    "Resposta intermediária: O craigslist foi fundado por Craig Newmark. \n",
    "Pergunta de acompanhamento: Quando nasceu Craig Newmark? \n",
    "Resposta intermediária: Craig Newmark nasceu em 6 de dezembro de 1952. \n",
    "Então a resposta final é: 6 de dezembro de 1952 \n",
    "\"\"\", \n",
    "    }, \n",
    "    {\"pergunta\": \"Quem foi o avô materno de George Washington?\",\n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem foi a mãe de George Washington? \n",
    "Resposta intermediária: A mãe de George Washington foi Mary Ball Washington. \n",
    "Pergunta de acompanhamento: Quem foi o pai de Mary Ball Washington? \n",
    "Resposta intermediária: O pai de Mary Ball Washington foi Joseph Ball. \n",
    "Então a resposta final é: Joseph Ball \n",
    "\"\"\", \n",
    "    },\n",
    "    {\"pergunta\": \"Os diretores de Jaws e Casino Royale são do mesmo país?\", \n",
    "     \"resposta\": \n",
    "\"\"\"São necessárias perguntas de acompanhamento aqui: Sim. \n",
    "Pergunta de acompanhamento: Quem é o diretor de Jaws? \n",
    "Resposta Intermediária: O diretor de Jaws é Steven Spielberg. \n",
    "Pergunta de acompanhamento: De onde é Steven Spielberg? \n",
    "Resposta Intermediária: Estados Unidos. \n",
    "Pergunta de acompanhamento: Quem é o diretor de Casino Royale? \n",
    "Resposta Intermediária: O diretor de Casino Royale é Martin Campbell. \n",
    "Pergunta de acompanhamento: De onde é Martin Campbell? \n",
    "Resposta Intermediária: Nova Zelândia. \n",
    "Então a resposta final é: Não \n",
    "\"\"\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ba05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "  input_variables=[\"pergunta\", \"resposta\"],\n",
    "  template=\"Pergunta: {pergunta}\\nResposta: {resposta}\\n\",\n",
    ")\n",
    "\n",
    "example_prompt.format(**exemplos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1e382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "  examples=exemplos,\n",
    "  example_prompt=example_prompt,\n",
    "  suffix=\"Pergunta: {input}\",\n",
    "  input_variables=[\"input\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.format(input=\"Quem fez mais gols, Romário ou Pelé?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(prompt.format(input=\"Quem fez mais gols, Romário ou Pelé?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a4c143",
   "metadata": {},
   "source": [
    "# Templates de Few-Shot Prompting para Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9258643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "  ('human', '{pergunta}'),\n",
    "  ('ai', '{resposta}'),\n",
    "])\n",
    "\n",
    "print(example_prompt.format_messages(**exemplos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1304c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_template = FewShotChatMessagePromptTemplate(\n",
    "  examples=exemplos,\n",
    "  example_prompt=example_prompt,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  few_shot_template,\n",
    "  (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "few_shot_template.format_messages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
