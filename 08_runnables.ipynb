{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f51c48",
   "metadata": {},
   "source": [
    "# Runnables\n",
    "\n",
    "No LangChain, os Runnables são componentes fundamentais que permitem a criação de cadeias de execução de tarefas, tornando o fluxo de dados mais eficiente e organizado. Entre os diversos tipos de Runnables disponíveis, três se destacam por sua funcionalidade e flexibilidade: RunnablePassthrough, RunnableLambda e RunnableParallel. Vamos explorar cada um deles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e76a0b",
   "metadata": {},
   "source": [
    "## Métodos dos Runnables de LCEL\n",
    "\n",
    "A interface padrão de LCEL inclui os seguintes métodos:\n",
    "\n",
    "- `stream`: transmitir de volta fragmentos da resposta\n",
    "\n",
    "- `invoke`: chamar a cadeia com um input\n",
    "\n",
    "- `batch`: chamar a cadeia com uma lista de inputs\n",
    "\n",
    "Esses também possuem métodos assíncronos correspondentes que devem ser usados com a sintaxe `asyncio await` para concorrência:\n",
    "\n",
    "- `astream`: transmitir de volta fragmentos da resposta de forma assíncrona\n",
    "\n",
    "- `ainvoke`: chamar a cadeia com um input de forma assíncrona\n",
    "\n",
    "- `abatch`: chamar a cadeia com uma lista de inputs de forma assíncrona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b339e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"Crie uma frase sobre o assunto: {assunto}\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f28d8f3",
   "metadata": {},
   "source": [
    "## Invoke\n",
    "\n",
    "O invoke é o método básico para inserir uma input na cadeia e receber uma resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8271e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"assunto\": \"Inteligência Artificial\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388177d3",
   "metadata": {},
   "source": [
    "Ele pode ser rodado como uma simples string quando existe apenas uma input no prompt, mas a forma mais recomendada é informando especificamente o nome da input através de um dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec889ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(\"cachorrinhos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7988ae73",
   "metadata": {},
   "source": [
    "## Stream\n",
    "\n",
    "Para recebermos uma saída conforme ela é gerada pelo modelo utilizamos o stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef618b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stream in chain.stream(\"cachorrinhos\"):\n",
    "  print(stream.content, end=\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ec0be",
   "metadata": {},
   "source": [
    "## Batch\n",
    "\n",
    "Para fazermos múltiplas requisições em paralelo utilizamos o batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35ca1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.batch([{'assunto': 'cachorrinhos'}, {'assunto': 'gatinhos'}, {'assunto': 'cavalinhos'}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9092dbc",
   "metadata": {},
   "source": [
    "## Runnables especiais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7fa20f",
   "metadata": {},
   "source": [
    "### Rodando em paralelo\n",
    "```\n",
    "     Input      \n",
    "      / \\       \n",
    "     /   \\      \n",
    " Branch1 Branch2\n",
    "     \\   /      \n",
    "      \\ /       \n",
    "      Combine   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75ae96",
   "metadata": {},
   "source": [
    "### RunnableParallel\n",
    "\n",
    "O RunnableParallel é um componente poderoso que permite executar múltiplos Runnables simultaneamente. Ele aceita um dicionário de Runnables e fornece a mesma entrada a todos eles, retornando um dicionário com os resultados correspondentes. Isso é especialmente útil quando você precisa realizar várias operações independentes ao mesmo tempo, economizando tempo em processos que podem ser feitos em paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f69305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"Crie um nome para o seguinte produto: {produto}\")\n",
    "\n",
    "chain_nome = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06cd4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"Descreva o cliente potencial para o seguinte produto: {produto}\")\n",
    "\n",
    "chain_clientes = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b4ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel = RunnableParallel({'nome_produto': chain_nome, 'publico': chain_clientes})\n",
    "parallel.invoke({'produto': 'Um copo inquebrável'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc334cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Dado o produto com o seguinte nome e seguinte\n",
    "público potencial, desenvolva um anúncio para o produto.\n",
    "                                          \n",
    "Nome do produto: {nome_produto}\n",
    "Público: {publico}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = parallel | prompt | ChatOpenAI() | StrOutputParser()\n",
    "chain.invoke({'produto': 'Um copo inquebrável'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb878ca",
   "metadata": {},
   "source": [
    "### RunnableLambda\n",
    "\n",
    "O RunnableLambda permite que você crie um Runnable a partir de uma função Python arbitrária. Isso é útil para encapsular qualquer lógica que você queira aplicar aos dados ou para transformar entradas em saídas de uma maneira específica. Um aspecto interessante do RunnableLambda é que ele pode ser construído para funcionar de forma síncrona ou assíncrona, dependendo de como a função é definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33428f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def cumprimentar(nome):\n",
    "    return f'Olá, {nome}!'\n",
    "\n",
    "runnable_cumprimentar = RunnableLambda(cumprimentar)\n",
    "\n",
    "resultado = runnable_cumprimentar.invoke('Maria')\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3a8b9",
   "metadata": {},
   "source": [
    "### RunnablePassthrough\n",
    "\n",
    "O RunnablePassthrough é um tipo de Runnable que simplesmente passa a entrada recebida como saída, podendo também adicionar chaves adicionais ao resultado. Ele se comporta quase como uma função de identidade, mas é útil em cenários onde você deseja incluir lógica adicional ou manipular a entrada de alguma forma antes de passar adiante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d76f785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Dado o produto com o seguinte nome e seguinte\n",
    "público potencial, desenvolva um anúncio para o produto.\n",
    "                                          \n",
    "Nome do produto: {nome_produto}\n",
    "Característica do produto: {produto}\n",
    "Público: {publico}\"\"\")\n",
    "\n",
    "parallel = RunnablePassthrough().assign(**{'nome_produto': chain_nome, 'publico': chain_clientes})\n",
    "chain = parallel | prompt | ChatOpenAI() | StrOutputParser()\n",
    "chain.invoke({'produto': 'Copo inquebrável'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
