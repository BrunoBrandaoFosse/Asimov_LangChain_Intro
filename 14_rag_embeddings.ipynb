{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aafcafb5",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "\n",
    "Os Embeddings criam uma representação vetorial de um pedaço de texto. Isso é útil porque significa que podemos pensar sobre o texto no espaço vetorial e fazer coisas como busca semântica, onde procuramos por pedaços de texto que são mais semelhantes no espaço vetorial, ou seja, que estão a uma distância menor.\n",
    "\n",
    "A classe Embeddings do Langchain é uma classe projetada para interagir com modelos de embedding de texto. Existem muitos modelos diferentes (OpenAI, Cohere, Hugging Face, etc) - esta classe é projetada para fornecer uma interface padrão para todos eles.\n",
    "\n",
    "A classe de Embeddings base em LangChain fornece dois métodos: um para realizar o emedding de documentos e outro para embedding de uma chamada. O primeiro recebe como entrada vários textos, enquanto o último recebe um único texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc902411",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/text_embedding/\n",
    "\n",
    "https://platform.openai.com/docs/guides/embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211392a",
   "metadata": {},
   "source": [
    "## Embeddings com OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# text-embedding-ada-002 (padrão do LangChain)\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617374f0",
   "metadata": {},
   "source": [
    "## Embedding documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da46fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model.embed_documents(\n",
    "  [\n",
    "    \"Eu gosto de cachorros\",\n",
    "    \"Eu gosto de animais\",\n",
    "    \"O tempo está ruim lá fora\",\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1101c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6587e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[0][:10] # mostra os primeiros 10 valores do vetor de embedding do primeiro texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243497ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings[0])  # mostra a dimensão do vetor de embedding do primeiro texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c8764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings[1])  # mostra a dimensão do vetor de embedding do segundo texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ddbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings[2]) # mostra a dimensão do vetor de embedding do terceiro texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3e9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "for emb in embeddings:\n",
    "  print(len(emb), max(emb), min(emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# similarity entre os dois primeiros textos\n",
    "# np.dot calcula o produto escalar entre os dois vetores\n",
    "np.dot(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd07593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embeddings[0], embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b92c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(embeddings[1], embeddings[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbc6260",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(embeddings)):\n",
    "  for j in range(len(embeddings)):\n",
    "    print(round(np.dot(embeddings[i], embeddings[j]), 2), end=\" | \")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995750c0",
   "metadata": {},
   "source": [
    "## Embedding query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = \"O que é um cachorro\"\n",
    "emb_query = embedding_model.embed_query(pergunta)\n",
    "emb_query[:10]  # mostra os primeiros 10 valores do vetor de embedding da query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce7a19",
   "metadata": {},
   "source": [
    "## Embedding com HuggingFace\n",
    "\n",
    "https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe752d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model.embed_documents(\n",
    "  [\n",
    "    \"Eu gosto de cachorros\",\n",
    "    \"Eu gosto de animais\",\n",
    "    \"O tempo está ruim lá fora\",\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59265e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "  for j in range(len(embeddings)):\n",
    "    print(round(np.dot(embeddings[i], embeddings[j]), 2), end=\" | \")\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for emb in embeddings:\n",
    "  print(len(emb), max(emb), min(emb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
