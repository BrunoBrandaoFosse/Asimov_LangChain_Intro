{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187494b8",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99902614",
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhos = [\n",
    "  'arquivos/Explorando o Universo das IAs com Hugging Face.pdf',\n",
    "  'arquivos/Explorando a API da OpenAI.pdf',\n",
    "  'arquivos/Explorando a API da OpenAI.pdf',\n",
    "]\n",
    "\n",
    "paginas = []\n",
    "\n",
    "for caminho in caminhos:\n",
    "  loader = PyPDFLoader(caminho)\n",
    "  paginas.extend(loader.load())\n",
    "\n",
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=500,\n",
    "  chunk_overlap=50,\n",
    "  separators=['\\n\\n', '\\n', '.', ' ', ''],\n",
    ")\n",
    "\n",
    "documents = recur_split.split_documents(paginas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577c95e",
   "metadata": {},
   "source": [
    "### Modificando metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata['source'] = doc.metadata['source'].replace('arquivos/', '')\n",
    "    doc.metadata['doc_id'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[2].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e5b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __import__('pysqlite3')\n",
    "# import sys\n",
    "# sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f9264",
   "metadata": {},
   "source": [
    "### Criando VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d37ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio = 'arquivos/chroma_retrival_bd'\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=diretorio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9c5401",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad975bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'O que é a OpenAI?'\n",
    "\n",
    "docs = vectordb.similarity_search(pergunta, k=3)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a27a1",
   "metadata": {},
   "source": [
    "### Limitações do semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b179e1",
   "metadata": {},
   "source": [
    "#### Trechos com muito similaridade e pouca infomação adicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'O que é a OpenAI?'\n",
    "\n",
    "docs = vectordb.similarity_search(pergunta, k=3)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86540db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'O que a apostila de Hugging Face fala sobre a OpenAI e o ChatGPT?'\n",
    "\n",
    "docs = vectordb.similarity_search(pergunta, k=3)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba85650",
   "metadata": {},
   "source": [
    "## MRR (Maximal Marginal Relevance)\n",
    "\n",
    "É uma técnica usada na busca de documentos (retrieval) para selecionar resultados que sejam ao mesmo tempo relevantes e diversos.\n",
    "Ou seja, o MRR evita que os documentos retornados sejam muito parecidos entre si, trazendo respostas mais variadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af27235",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'O que é a OpenAI?'\n",
    "\n",
    "\"\"\"\n",
    "O parâmetro fetch_k em vectordb.max_marginal_relevance_search(pergunta, k=3, fetch_k=10) \n",
    "define quantos documentos serão considerados inicialmente antes de selecionar os k finais \n",
    "mais relevantes e diversos.\n",
    "Ou seja:\n",
    "  - Primeiro, o método busca os fetch_k documentos mais semelhantes.\n",
    "  - Depois, desses, escolhe os k que têm maior diversidade de informação (maximal marginal relevance).\n",
    "\"\"\"\n",
    "docs = vectordb.max_marginal_relevance_search(pergunta, k=3, fetch_k=10)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5086d2",
   "metadata": {},
   "source": [
    "## Filtragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'O que a apostila de Hugging Face fala sobre a OpenAI e o ChatGPT?'\n",
    "\n",
    "\"\"\"\n",
    "O parâmetro filter={'source': 'Explorando o Universo das IAs com Hugging Face.pdf'} serve para \n",
    "filtrar os documentos buscados, retornando apenas aqueles cuja metadata source seja igual ao \n",
    "nome do arquivo especificado.\n",
    "\n",
    "Ou seja, só serão considerados documentos que vieram do arquivo \n",
    "\"Explorando o Universo das IAs com Hugging Face.pdf\".\n",
    "Isso permite buscar informações apenas em um documento específico, ignorando os demais.\n",
    "\"\"\"\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    pergunta, \n",
    "    k=3,\n",
    "    filter={'source': 'Explorando o Universo das IAs com Hugging Face.pdf'})\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a98209",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'O que a apostila de Hugging Face fala sobre a OpenAI e o ChatGPT?'\n",
    "\n",
    "\"\"\"\n",
    "filter={'source': {'$in': ['Explorando o Universo das IAs com Hugging Face.pdf']}})\n",
    "Igual ao exemplo anterior, mas usando o operador $in para permitir múltiplos arquivos.\n",
    "\"\"\"\n",
    "docs = vectordb.similarity_search(\n",
    "    pergunta, \n",
    "    k=3,\n",
    "    filter={'source': {'$in': ['Explorando o Universo das IAs com Hugging Face.pdf']}})\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'O que a apostila de Hugging Face fala sobre a OpenAI e o ChatGPT?'\n",
    "\n",
    "\"\"\"\n",
    "Dupla filtragem: fonte e páginas específicas.\n",
    "\"\"\"\n",
    "docs = vectordb.similarity_search(\n",
    "    pergunta, \n",
    "    k=3,\n",
    "    filter={'$and':\n",
    "            [{'source': {'$in': ['Explorando o Universo das IAs com Hugging Face.pdf']}},\n",
    "            {'page': {'$in': [10, 11, 12, 13]}}],\n",
    "            })\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a784c",
   "metadata": {},
   "source": [
    "## LLM Aided Retrieval\n",
    "\n",
    "LLM Aided Retrieval é uma técnica onde um modelo de linguagem (LLM, como GPT) ajuda a melhorar a busca de informações em uma base de dados ou documentos.\n",
    "\n",
    "Em vez de só usar busca por similaridade de vetores, o LLM pode:\n",
    "\n",
    "- Gerar queries melhores ou mais detalhadas.\n",
    "- Reformular perguntas para encontrar respostas mais relevantes.\n",
    "- Filtrar ou classificar resultados usando inteligência do modelo.\n",
    "\n",
    "No LangChain, LLM Aided Retrieval combina o poder dos LLMs com métodos tradicionais de busca, tornando o processo de recuperação de informações mais inteligente e preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b60c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_info = [\n",
    "    AttributeInfo(\n",
    "        name='source',\n",
    "        description='Nome da apostila de onde o texto original foi retirado. Deve ter o valor de: \\\n",
    "            Explorando o Universo das IAs com Hugging Face.pdf ou Explorando a API da OpenAI.pdf',\n",
    "        type='string'\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name='page',\n",
    "        description='A página da apostila de onde o texto se origina',\n",
    "        type='integer'\n",
    "    ),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_description = 'Apostilas de cursos'\n",
    "llm = OpenAI()\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_description,\n",
    "    metadata_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'O que a apostila de Hugging Face fala sobre a OpenAI e o ChatGPT?'\n",
    "\n",
    "docs = retriever.invoke(pergunta)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671eb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = 'Quais detalhes são descritos na página 44 da apostila Explorando a API da OpenAI?'\n",
    "\n",
    "docs = retriever.invoke(pergunta)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8067c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "pergunta = 'Quais detalhes são descritos na página 44 da apostila Explorando a API da OpenAI?'\n",
    "\n",
    "docs = retriever.invoke(pergunta)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(f'==========={doc.metadata}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "_json = '{\\n    \\\"query\\\": \\\"detalhes\\\",\\n    \\\"filter\\\": \\\"and(eq(\\\\\\\"source\\\\\\\", \\\\\\\"Explorando a API da OpenAI.pdf\\\\\\\"), eq(\\\\\\\"page\\\\\\\", 44))\\\"\\n}'\n",
    "print(json.dumps(json.loads(_json), indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
