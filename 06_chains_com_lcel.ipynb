{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10e8309",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)\n",
    "\n",
    "A Linguagem de Expressão LangChain, ou LCEL, é uma forma declarativa de **compor cadeias de maneira fácil**. A LCEL foi projetada desde o primeiro dia para suportar a colocação de protótipos em produção, sem a necessidade de alterações no código, desde a cadeia mais simples “prompt + LLM” até as cadeias mais complexas (já vimos pessoas executando com sucesso cadeias LCEL com centenas de etapas em produção). Para destacar alguns dos motivos pelos quais você pode querer usar a LCEL:\n",
    "\n",
    "- `Suporte a streaming de primeira classe`: menor tempo possível para saída do primeiro token produzido;\n",
    "\n",
    "- `Suporte assíncrono`: qualquer cadeia construída com a LCEL pode ser chamada tanto com a API síncrona;\n",
    "\n",
    "- `Execução paralela otimizada`: sempre que suas cadeias LCEL tiverem etapas que podem ser executadas em paralelo, automaticamente é feito isso;\n",
    "\n",
    "- `Retentativas e fallbacks`: é maneira de tornar suas cadeias mais confiáveis em grande escala, na qual ações alternativas podem ser tomadas no caso de um erro em uma cadeia\n",
    "\n",
    "- `Acessar resultados intermediários`: auxiliando na depuração de uma cadeia;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c356eb0d",
   "metadata": {},
   "source": [
    "## Um exemplo simples de LCEL\n",
    "\n",
    "O exemplo mais simples que podemos mostrar seria na construção de promt + model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Crie uma frase sobre o seguinte assunto: {assunto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"assunto\": \"Inteligência Artificial\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b03ffe",
   "metadata": {},
   "source": [
    "## Adicionando mais elementos a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19127752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"assunto\": \"Inteligência Artificial\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Crie uma frase sobre o seguinte assunto: {assunto}\")\n",
    "\n",
    "chain = prompt | ChatOpenAI() | StrOutputParser()\n",
    "\n",
    "chain.invoke({\"assunto\": \"Cachorro\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b100b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.input_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdcb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.output_schema.model_json_schema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
