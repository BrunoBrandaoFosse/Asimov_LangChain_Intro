{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d04cc4",
   "metadata": {},
   "source": [
    "# Output Parsers - Formatando saídas\n",
    "\n",
    "Como retornar dados estruturados de um modelo?\n",
    "\n",
    "É frequentemente útil que um modelo retorne uma saída que corresponda a um esquema específico. Um caso de uso comum é a extração de dados de um texto para inseri-los em um banco de dados ou utilizá-los em algum outro sistema subsequente. Nesta aula abordaremos algumas estratégias para obter saídas estruturadas de um modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847d686",
   "metadata": {},
   "source": [
    "## Estruturando saídas de chat - StrOutputParser\n",
    "\n",
    "O formatador mais simples do LangChain é o StrOutputParser. Ele é utilizado para convertermos saídas do modelo no formato de conversão para formato texto. É uma atividade bem comum, levando em consideração que maior parte das LLMs que utlizamos com LangChain são acessadas através dos ChatModels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente engraçado e se chama {nome_assistente}\"),\n",
    "    (\"human\", \"{pergunta}\"),\n",
    "])\n",
    "\n",
    "chat_template.format_messages(nome_assistente=\"Asimov\", pergunta=\"Qual é o seu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c73033",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = chat_template.invoke({\n",
    "  'nome_assistente': 'Asimov',\n",
    "  'pergunta': 'Qual é o seu nome?'\n",
    "})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "resposta = chat.invoke(prompt)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f140232e",
   "metadata": {},
   "source": [
    "## StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475cbeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "output_parser.invoke(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3302b9",
   "metadata": {},
   "source": [
    "## Dando um spoiler de chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1561099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output de chat_template passa para chat, que passa para output_parser.\n",
    "chain = chat_template | chat | output_parser\n",
    "\n",
    "chain.invoke({\n",
    "  'nome_assistente': 'Asimov',\n",
    "  'pergunta': 'Qual é o seu nome?'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c67d7",
   "metadata": {},
   "source": [
    "## Estruturando saídas mais complexas - Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54726097",
   "metadata": {},
   "source": [
    "### Utilizando .with_stractured_output()\n",
    "\n",
    "Esta é a maneira mais fácil e confiável de obter saídas estruturadas. O método with_structured_output() é implementado para modelos que fornecem APIs nativas para estruturar saídas, como chamadas de ferramentas/funções ou modo JSON, e aproveita essa capacidades internamente.\n",
    "\n",
    "Este modelo recebe um esquema como entrada, que específica os nomes, tipos e descrições dos atributos desejados na saída. Ele retorna um objeto similar a um Runnable, exceto que, em vez de gerar strings ou mensagens, produz objetos correspondentes ao esquema fornecido. O esquema pode ser especificado como uma classe TypedDict, um JSON Schema ou uma classe Pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic é usado para validação de dados\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "class Piada(BaseModel):\n",
    "  \"\"\"Piada para contar aos usuários\"\"\"\n",
    "  introducao: str = Field(description=\"A introdução da piada\")\n",
    "  piada: str = Field(description=\"A conclusão da piada\")\n",
    "  avaliacao: Optional[int] = Field(description=\"O quão engraçado é a piada de 0 a 10?\")\n",
    "\n",
    "llm_estruturada = chat.with_structured_output(Piada)\n",
    "resposta = llm_estruturada.invoke(\"Conte uma piada sobre programadores\")\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c21ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Introdução: {resposta.introducao}\")\n",
    "print(f\"Piada: {resposta.piada}\")\n",
    "print(f\"Avaliação: {resposta.avaliacao}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98314ef",
   "metadata": {},
   "source": [
    "## Um exemplo mais prático\n",
    "\n",
    "Digamos que temos a seguinte review de um produto:\n",
    "\n",
    "> \"Este soprador de folhas é bastante incrível. Ele tem quatro configurações: sopro de vela, brisa suave, cidade ventosa e tornado. Chegou em dois dias, bem a tempo para o presente de aniversário da minha esposa. Acho que minha esposa gostou tanto que ficou sem palavras. Até agora, fui o único a usá-lo, e tenho usado em todas as manhãs alternadas para limpar as folhas do nosso gramado. É um pouco mais caro do que os outros sopradores de folhas disponíveis no mercado, mas acho que vale a pena pelas características extras.\"\n",
    "\n",
    "E eu quero que o modelo de linguagem processe esta review para estruturá-la no seguinte formato:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"presente\": true,\n",
    "  \"dias_entrega\": 2,\n",
    "  \"percepcao_de_valor\": [\"um pouco mais caro do que os outros sopradores de folhas disponíveis no mercado\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14580b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cliente = \"\"\"Este soprador de folhas é bastante incrível. Ele tem \n",
    "quatro configurações: sopro de vela, brisa suave, cidade ventosa \n",
    "e tornado. Chegou em dois dias, bem a tempo para o presente de \n",
    "aniversário da minha esposa. Acho que minha esposa gostou tanto \n",
    "que ficou sem palavras. Até agora, fui o único a usá-lo, e tenho \n",
    "usado em todas as manhãs alternadas para limpar as folhas do \n",
    "nosso gramado. É um pouco mais caro do que os outros sopradores \n",
    "de folhas disponíveis no mercado, mas acho que vale a pena pelas \n",
    "características extras.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class AvaliacaoReview(BaseModel):\n",
    "    \"\"\"Avalia review do cliente\"\"\"\n",
    "    presente: bool = Field(description='Verdadeiro se foi para presente e False se não foi')\n",
    "    dias_entrega: int = Field(description='Quantos dias para entrega do produto')\n",
    "    percepcao_valor: list[str] = Field(description='Extraia qualquer frase sobre o valor ou \\\n",
    "    preço do produto. Retorne uma lista.')\n",
    "\n",
    "llm_estruturada = chat.with_structured_output(AvaliacaoReview)\n",
    "resposta = llm_estruturada.invoke(review_cliente)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Avaliacao(BaseModel):\n",
    "    \"\"\"Avaliação do produto com base no review do cliente\"\"\"\n",
    "    descricao_produto: str = Field(description=\"Breve descrição do produto\")\n",
    "    entrega: bool = Field(description=\"Cliente ficou satisfeito com a entrega\")\n",
    "    produto: bool = Field(description=\"Cliente ficou satisfeito com o produto\")\n",
    "    atendimento: bool = Field(description=\"Cliente ficou satisfeito com o atendimento\")\n",
    "    satisfacao: int = Field(description=\"Satisfação geral do cliente com a compra\")\n",
    "\n",
    "llm_estruturada = chat.with_structured_output(Avaliacao)\n",
    "resposta = llm_estruturada.invoke(review_cliente)\n",
    "resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Descrição: {resposta.descricao_produto}\")\n",
    "print(f\"Entrega: {resposta.entrega}\")\n",
    "print(f\"Produto: {resposta.produto}\")\n",
    "print(f\"Atendimento: {resposta.atendimento}\")\n",
    "print(f\"Satisfação: {resposta.satisfacao}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
